**ğŸ” Search Engine using LangChain Tools & Agents**

A Search Engine powered by LangChain tools and agents that retrieves information from a real dataset and generates context-aware, hallucination-minimized answers using a Retrieval-Augmented Generation (RAG) approach.

This project demonstrates how LLM agents dynamically invoke tools to perform search and reasoning, making it a practical example of agentic GenAI applications.

_________________________________________________________

**ğŸš€ Features**

ğŸ” Tool-based search using LangChain Agents

ğŸ§  Retrieval-Augmented Generation (RAG) for accurate responses

ğŸ“š Answers generated strictly from retrieved context

âš¡ Groq-powered LLaMA LLM for fast inference

ğŸ–¥ï¸ Interactive UI built with Streamlit

_________________________________________________________

**ğŸ› ï¸ Tech Stack**

LangChain â€“ Tools, Agents, and RAG pipeline

Groq LLM â€“ LLaMA models for response generation

Vector Store â€“ For semantic search and retrieval

Streamlit â€“ Frontend UI

Python â€“ Core programming language
__________________________________________________________

**ğŸ§  Architecture Overview**

User Query
   â†“
LangChain Agent
   â†“
Tool Invocation (Search / Retriever)
   â†“
Relevant Context Retrieved
   â†“
LLM (Groq - LLaMA)
   â†“
Final Answer (Context-aware)
